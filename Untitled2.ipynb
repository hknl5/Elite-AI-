{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2cca663-90fc-4709-80ba-1f9bf0f6b7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (1.35.10)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ad18b7a-841d-4cf1-a7e8-c974746d6963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in /opt/anaconda3/lib/python3.12/site-packages (3.10.4)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from SpeechRecognition) (2.32.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.12/site-packages (from SpeechRecognition) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->SpeechRecognition) (2024.6.2)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition pydub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4d1b41b-2ef1-41b1-985b-62de14e926d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (738809506.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install transformers\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n",
    "pip install PyMuPDF\n",
    "pip install scikit-learn\n",
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "618f83e7-6787-4ba5-b4dc-531244acde8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "النص المحول:  in conclusion our participation in the zero which city tracks highlights over dedication to building sustainable cities and adjusting the pressing issue of plastic waste to our innovative solution we are giving the transition towards a future where the US cities becomes reality together\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# تحديد مسار الملف الصوتي المرفوع\n",
    "audio_file = \"/Users/amiraalqabba/Desktop/ghadi.wav\"  # تغيير إلى مسار الملف الصوتي الخاص بك\n",
    "\n",
    "# إنشاء كائن للتعرف على الكلام\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# استخدام الملف الصوتي المرفوع\n",
    "with sr.AudioFile(audio_file) as source:\n",
    "    audio = recognizer.record(source)  # تسجيل الصوت من الملف الصوتي\n",
    "\n",
    "try:\n",
    "    # تحويل الصوت إلى نص باستخدام خدمة جوجل\n",
    "    text = recognizer.recognize_google(audio, language='en-US')  # تحديد اللغة حسب الحاجة (الإنجليزية في هذه الحالة)\n",
    "    print(\"النص المحول: \", text)\n",
    "\n",
    "except sr.UnknownValueError:\n",
    "    print(\"لا يمكن فهم الصوت\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"خطأ في الاتصال بخدمة جوجل: {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ec4624d-9f06-4050-9942-2eeef9a9e6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "النص المحول من الصوت:  in conclusion our participation in the zero which city tracks highlights over dedication to building sustainable cities and adjusting the pressing issue of plastic waste to our innovative solution we are giving the transition towards a future where the US cities becomes reality together\n",
      "\n",
      "النص المستخرج من ملف PDF:  ECOSWAP\n",
      "We made plastic,\n",
      " We depend on it,\n",
      " Now we’re drowning in it !\n",
      "Plastic pollution arises when plastic waste is improperly\n",
      "disposed of or managed. Each year, an estimated 8\n",
      "million metric tons of plastic enter the oceans, which is\n",
      "equivalent to dumping one garbage truck of plastic into\n",
      "the ocean every minute. If this trend continues, it is\n",
      "projected that by 2050, there could be more plastic than\n",
      "fish in the oceans by weight.\n",
      "Plastic pollution arises when plastic waste is improper\n",
      "ly disposed of or managed. Each year, an estimated 8 million metric tons of plastic enter the oceans, which is equivalent to dumping one garbage truck of plastic into the ocean every minute. If this trend continues, it is projected that by 2050, there could be more plastic than fish in the oceans by weight.\n",
      "Almost 99% of plastic is created from chemicals de\n",
      "rived from fossil fuels.\n",
      "Each stage of the plastic manufacturing process is damaging to the ecosystem and climate.\n",
      "Introduction\n",
      "Plastic Recycling and\n",
      "Waste Management\n",
      "Traditional Waste management\n",
      "Waste is considered as the end of the resource\n",
      "life cycle.\n",
      "Perceives waste as mainly a technological\n",
      "problem and thus often relies on engineering\n",
      "solutions (landfill, incineration)\n",
      "Waste is considered as the end of the resou\n",
      "rce life cycle.\n",
      "Perceives waste as mainly a technologica\n",
      "l problem and thus often relies on engineering solutions (landfill, incineration)\n",
      "Highly depends on landfill and incineration technologies\n",
      "Allows resource depletion for recovering reso\n",
      "urces from waste, e.g. waste-to-energy.\n",
      "Perceives waste as both social and\n",
      "technological problem and thus seeks social\n",
      "technology (e.g. reuse/recycling) as well as\n",
      "engineering solutions\n",
      "Highly depends on waste avoidance and\n",
      "prohibits landfill and incineration\n",
      "technologies.\n",
      "Waste is considered as resource in t\n",
      "ransition or an intermediate phase of a reso\n",
      "urce life cycle.\n",
      "Perceives waste as both social and technological proble\n",
      "m and thus seeks social technology (e.g. reuse/recycling) a\n",
      "s well as engineering solutions\n",
      "Highly depends on waste avoidance and prohibits landfill an\n",
      "d incineration technologies.\n",
      "Conservation of resources instead of depletion, e.g. reuse an\n",
      "d recycle instead of waste-to-energy\n",
      " \n",
      "Plastic waste presents significant challenges for waste management systems. it is difficult to handle, process, and dispose of properly. \n",
      "Introducing\n",
      "In response to the alarming environmental repercussions of the escalating plastic production, which have ravaged ecosystems, marine biodiversity, and human health, we proudly unveil our pioneering platform, \"EcoSwap.\" \n",
      "This cutting-edge solution represents a p\n",
      "ivotal shift in our commitment to combating the glo\n",
      "bal plastic waste crisis, emphasizing sustainabilit\n",
      "y and environmental responsibility at its core.\n",
      "This cutting-edge solution represents a pivotal shift in\n",
      "our commitment to combating the global plastic waste\n",
      "crisis, emphasizing sustainability and environmental\n",
      "responsibility at its core.\n",
      "So, what is EcoSwap?  \n",
      "EcoSwap is an innovative platform that utilizes an advanced\n",
      "Artificial Neural Network (ANN) model and a ML\n",
      "Classification model to predict and recommend eco-friendly\n",
      "alternatives to specific types of plastic materials. Supporting\n",
      "Green Economy and Circular Economy.\n",
      "EcoSwap is an innovative platform that utilizes an advanced Artificial Neural Network (ANN) model and a ML Classification model to predict and recommend eco-friendly alternatives to specific types of plastic materials. Supporting Green Economy and Circular Economy.\n",
      "Revolutionizing Sustainability with\n",
      "Eco-Friendly Material Alternatives\n",
      "    By harnessing the power of this technology, EcoSwap\n",
      "provides users with valuable insights, including detailed\n",
      "specifications of the recommended materials, key factors\n",
      "influencing their selection, and real-world manufacturers\n",
      "illustrating their successful applications as replacements for\n",
      "traditional plastics as well as increasing accessibility to such\n",
      "materials and much more !\n",
      "EcoSwap \n",
      "    By harnessing the power of this\n",
      " technology, EcoSwap provides users with valuable insights, including detailed specifications of the recommended materials, key factors influencing their selection, and real-world manufacturers illustrating their successful applications as replacements for traditional plastics as well as increasing accessibility to such materials and much more !\n",
      "Introduction\n",
      "Artificial Intellegence Integration in plastic solutions \n",
      "Customized ANN Model: is a computational model inspired by the structure and\n",
      " function of biological neural networks in the human brain. It consists o\n",
      "f interconnected nodes, referred to as artificial neurons or \"units,\" organized \n",
      "in layers. The ANN model in EcoSwap is designed to learn from the collected data\n",
      "set of labelled examples.\n",
      "Training the ANN Model: During the training process, supervised learning is\n",
      "involved using the labelled dataset of nanocomposite compositions and\n",
      "properties. The model learns the relationships between composition and eco-\n",
      "friendly properties, minimizing prediction errors through weight adjustments\n",
      "and optimization.\n",
      "Making Accurate Predictions: Once the ANN model in EcoSwap is trained, it can\n",
      "make accurate predictions and recommendations for suitable eco-friendly\n",
      "nanocomposites as substitutes for specific types of plastic. By inputting the\n",
      "composition details of a plastic material, the ANN model utilizes its learned\n",
      "knowledge to predict and recommend the most appropriate nanocomposites\n",
      "that exhibit desirable eco-friendly properties\n",
      "Data Collection and Pre-processing \n",
      "Gather comprehensive data on material properties,\n",
      "environmental impact, and performance metrics of existing\n",
      "plastic substitutes.\n",
      "Preprocess the data to ensure accuracy and compatibility\n",
      "with the EcoSwap platform.\n",
      "EcoSwap draws relations using the ML Classification model.\n",
      "Data Collection and Pre-processing \n",
      "Gather comprehensive data on material properties, environment\n",
      "al impact, and performance metrics of existing plastic su\n",
      "bstitutes.\n",
      "Preprocess the data to ensure accuracy and compatibility wi\n",
      "th the EcoSwap platform.\n",
      "ML Classification model and Artificial Neural Netw\n",
      "ork (ANN) Model Integration \n",
      "While the ML classification model shows the already developed\n",
      "materials\n",
      "ML Classification model and Artificial\n",
      "Neural Network (ANN) Model Integration \n",
      "EcoSwap draws relations using the ML Classification model.\n",
      "EcoSwap also seamlessly incorporates an advanced ANN model, leveraging its learning capabilities and adaptability.\n",
      "Train the ANN model using the collected data to make accurate predictions and recommendations for suitable eco-friendly nanocomposites as substitutes for specific types of plastic materials\n",
      "Iterative Improvement\n",
      "Continuously refines the ML models using feedback from\n",
      "material testing and user evaluations enhancing the\n",
      "accuracy and efficiency of the model over time. \n",
      "Users are struggling in\n",
      "finding plastic\n",
      "substitutes \n",
      "They find ECOSWAP and start\n",
      " searching for materials, eithe\n",
      "r in the ECOSWAP search engi\n",
      "ne or using the ECOSWAP Chatbot\n",
      "The extracted information i\n",
      "s processed using ECOSWAP special \n",
      "ML algorithms to draw relations bet\n",
      "ween the searched item and ite\n",
      "ms in the ECOSWAP database.\n",
      "The extracted information is\n",
      "processed using ECOSWAP\n",
      "special ML algorithms to draw\n",
      "relations between the searched\n",
      "item and items in the ECOSWAP\n",
      "database.\n",
      "ECOSWAP generate results and\n",
      "display as a list of web pages, or\n",
      "a text if the user is using the\n",
      "ECOSWAP Chatbot\n",
      "Story Board\n",
      "When the user first visit the ECOSWAP\n",
      "website, the home page appears.\n",
      "The home page includes interesting sections\n",
      "that will get the user excited such as a\n",
      "trending section with popular materials.\n",
      "When the user first visit the ECOSWAP website, the home page appears.\n",
      "And  a section for the leading bioplastic\n",
      "manifacuteres.\n",
      "And  a section for the leading bioplas\n",
      "tic manifacuteres.\n",
      "In the footer encourging words are yet again displayed, and important information about the website are displayed.\n",
      "They are also kept engaged with recommendat\n",
      "ions taps, such as (“Our picks”, “Last Searc\n",
      "h”, “Trending”, “Highest reviewed“).\n",
      "They are also kept engaged with\n",
      "recommendations taps, such as (“Our\n",
      "picks”, “Last Search”, “Trending”, “Highest\n",
      "reviewed“).\n",
      "Application\n",
      "Next to every material a “Read more” button can be f\n",
      "ound to have a more comprehensive view on said material\n",
      ".\n",
      "Next to every material a “Read more”\n",
      "button can be found to have a more\n",
      "comprehensive view on said material.\n",
      "Application\n",
      "If the user chose the “Read more” button\n",
      "they will be transferred to page with all the\n",
      "material’s details.\n",
      "A comprehensive description as well as a\n",
      "research tap will be available; in the research\n",
      "tap the user can find related articles on the\n",
      "material.a list of the material’s properties, and\n",
      "where is it manufactured will also be displayed.\n",
      "If the user chose the “Read more” button they will be transferred to page with all the material’s details.\n",
      "Now for the users who are not experts in the\n",
      "scientific terminology, the ECOSWAP\n",
      "chatbot would be the best fit.\n",
      "Now for the users who are not experts in the s\n",
      "cientific terminology, the ECOSWAP chatbot w\n",
      "ould be the best fit.\n",
      "in the ECOSWAP chatbot users can enter similar entries as in the search engine, but further discussions can be done, if users don’t really understand a certain material composition they can further investigate it with our chatbot.\n",
      "Catalyst that allows other ideas to thrive\n",
      " EcoSwap fosters a community of like-minded businesses.\n",
      "This network promotes knowledge-sharing, best practices,\n",
      "and the development of innovative sustainable solutions.\n",
      "Data-Driven Decision-Making\n",
      "Utilizing our models, our approach empowers data-\n",
      "driven decision-making by providing accurate and\n",
      "dependable recommendations.\n",
      " EcoSwap fosters a community of like-minded businesses. This network promotes knowledge-sharing, best practices, and the development of innovative sustainable solutions.\n",
      "Utilizing our models, our approach empowers data-driven decision-making by providing accurate and dependable recommendations.\n",
      "B\n",
      "D\n",
      "A\n",
      "B\n",
      "Collaborative Sustainability Network\n",
      "Our platform will serve as a cornerstone for the thriving of\n",
      "other platforms. While we strive to develop numerous plastic\n",
      "substitutes, their true value lies in accessibility. After all, what\n",
      "purpose would they serve if they are not easily attainable?\n",
      "C\n",
      "D\n",
      "Developed Countries\n",
      "Undeveloped Countries\n",
      "Ecoswap’s accessibility and applicability make it a valuable solution\n",
      "for both developed and undeveloped countries. irrespective of the\n",
      "economic resources available.This levels the playing field and\n",
      "empowers countries at various levels of development to make\n",
      "informed decisions and take steps towards sustainable practices.\n",
      "Ecoswap’s accessibility and applicability make it a valuable soluti\n",
      "on for both developed and undeveloped countries. irrespective of the \n",
      "economic resources available.This levels the playing field an\n",
      "d empowers countries at various levels of development to make informed decisions and take steps towards sustainable practices.\n",
      "EcoSwap's replicability stems from its underlying technology, which u\n",
      "tilizes an advanced ML Classification model and an Artificial Neur\n",
      "al Network (ANN) model. These models can be trained and deployed ac\n",
      "ross various platforms and industries with relative ease.\n",
      "EcoSwap Feasibility lies in its ability to access comprehensive data, train accurate ML models, and provide reliable recommendations for plastic substitutes. By incorporating stakeholder collaboration and scalability while optimizing costs and resources, we ensure the practicality and sustainability of our solution.\n",
      "Undeveloped Countries\n",
      "Our participation in the 'Zero Waste City' track highlights our dedication to building\n",
      " sustainable cities and addressing the pressing issue of plastic waste. Through ou\n",
      "r innovative solution, EcoSwap, we are driving the transition towards a future where 'Ze\n",
      "ro Waste Cities' become a reality.\n",
      "By leveraging advanced technologies, EcoSwap recommends eco-friendly alternatives to\n",
      " specific plastic materials, revolutionizing material selection and usage.\n",
      "Our platform streamlines the development process, providing users with comprehensive\n",
      " insights to make informed decisions that contribute to a sustainable future. With a focu\n",
      "s on responsible resource management and reducing plastic waste, we aim to create citi\n",
      "es where environmental consciousness and urban development are harmoniou\n",
      "sly integrated. Together, we can inspire change and build a future of thriving 'Zero W\n",
      "aste Cities'.\n",
      "Conclusion\n",
      "Thank You!\n",
      "Supervised By\n",
      "Team Members\n",
      "GHADI HERSI\n",
      "DR.MOHAMMED ALFLEET\n",
      "WAREEF  \n",
      "MOHAMMED\n",
      "GHADI HERSI\n",
      "SARAH S\n",
      "ALIM\n",
      "References\n",
      "P.G.C. Nayanathara Thathsarani Pilapitiya, Amila\n",
      " Sandaruwan Ratnayake (2024) The world of plastic waste\n",
      ": A review. Available a\n",
      "t: https://www.sciencedirect.com/science/article/pii/S2772\n",
      "397624000042\n",
      "Md. Golam Kibria, Nahid Imtiaz Masuk,Rafat Safayet,Huy\n",
      " Quoc Nguyen, and Monjur Mourshed(2023) Plastic Waste\n",
      ": Challenges and Opportunities to Mitigate Pollution a\n",
      "nd Effective Management. Available \n",
      "at: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9857911/\n",
      "Dr. András Szeberényi, Bhgah Y. Adam, Er. Harish Sharma,\n",
      " Dr Dhivya A(2023) PLASTIC RECYCLING & WAST\n",
      "E MANAGEMENT Availab\n",
      "le at:https://www.researchgate.net/publication/374118314_\n",
      "PLASTIC_RECYCLING_WASTE_MANAGEMENT \n",
      "Nirban Laskar(2019) Plastics and microplastics: A threat to\n",
      " environment Available at\n",
      ": https://www.sciencedirect.com/science/article/abs/pii/S235\n",
      "2186418302748\n",
      "I Beauchesne , S Barnabé, D G Cooper, J A Nicell (2008)\n",
      " Plasticizers and related toxic degradation products i\n",
      "n wastewater sludges Available a\n",
      "t: https://pubmed.ncbi.nlm.nih.gov/18309214/\n",
      "Tianle Chen, Zhenqian Pang, Shuaiming He, Yang Li,\n",
      " Snehi Shrestha, Joshua M. Little, Haochen Yang, Tsai\n",
      "-Chun Chung, Jiayue Sun, Hayden Christopher Whitley, I\n",
      "-Chi Lee, Taylor J. Woehl, Teng Li, Liangbing Hu & Po-Ye\n",
      "n Chen (2024) Machine intelligence-accelerated discovery \n",
      "of all-natural plastic substitutes Available \n",
      "at: https://www.nature.com/articles/s41565-024-01635-z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import fitz  \n",
    "\n",
    "audio_file = \"/Users/amiraalqabba/Desktop/ghadi.wav\"  # تغيير إلى مسار الملف الصوتي الخاص بك\n",
    "pdf_file = \"/Users/amiraalqabba/Desktop/Ecoswap.pdf\"  # تغيير إلى مسار ملف الـ PDF الخاص بك\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "\n",
    "with sr.AudioFile(audio_file) as source:\n",
    "    audio = recognizer.record(source)  # تسجيل الصوت من الملف الصوتي\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_file)\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "        doc.close()\n",
    "    except Exception as e:\n",
    "        text = f\"Error extracting text from PDF: {str(e)}\"\n",
    "    return text\n",
    "\n",
    "try:\n",
    "    # تحويل الصوت إلى نص باستخدام خدمة جوجل\n",
    "    audio_text = recognizer.recognize_google(audio, language='en-US')  # تحديد اللغة حسب الحاجة (الإنجليزية في هذه الحالة)\n",
    "    print(\"النص المحول من الصوت: \", audio_text)\n",
    "    \n",
    "    # استخراج النص من ملف PDF\n",
    "    pdf_text = extract_text_from_pdf(pdf_file)\n",
    "    print(\"\\nالنص المستخرج من ملف PDF: \", pdf_text)\n",
    "\n",
    "except sr.UnknownValueError:\n",
    "    print(\"لا يمكن فهم الصوت\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"خطأ في الاتصال بخدمة جوجل: {0}\".format(e))\n",
    "except Exception as e:\n",
    "    print(f\"حدث خطأ أثناء استخراج النص: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49f35a91-384d-423f-aa68-5df6ef4d7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in /opt/anaconda3/lib/python3.12/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (4.66.4)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61938018-aeb8-4776-a2e4-cfd9c55c111c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (1.35.10)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b50343d-6d8c-4191-a002-8d4d045bea81",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 123\u001b[0m\n\u001b[1;32m    120\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/amiraalqabba/Desktop/ghadi.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m pdf_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/amiraalqabba/Desktop/Ecoswap.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 123\u001b[0m results \u001b[38;5;241m=\u001b[39m main(audio_file, pdf_file)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# طباعة النتائج\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(results, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "Cell \u001b[0;32mIn[47], line 85\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(audio_file, pdf_file)\u001b[0m\n\u001b[1;32m     82\u001b[0m slides_text \u001b[38;5;241m=\u001b[39m extract_text_from_pdf(pdf_file)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# استخراج النقاط الرئيسية\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m key_points_audio \u001b[38;5;241m=\u001b[39m extract_key_points(audio_text)\n\u001b[1;32m     86\u001b[0m key_points_slides \u001b[38;5;241m=\u001b[39m extract_key_points(slides_text)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# حساب التشابه النصي\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[47], line 55\u001b[0m, in \u001b[0;36mextract_key_points\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_key_points\u001b[39m(text):\n\u001b[1;32m     54\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract key points from the following text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 55\u001b[0m     key_points \u001b[38;5;241m=\u001b[39m call_openai_api(prompt)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key_points\n",
      "Cell \u001b[0;32mIn[47], line 32\u001b[0m, in \u001b[0;36mcall_openai_api\u001b[0;34m(prompt, max_tokens)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_openai_api\u001b[39m(prompt, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m):\n\u001b[0;32m---> 32\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     33\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}],\n\u001b[1;32m     35\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import speech_recognition as sr\n",
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "\n",
    "\n",
    "openai.api_key = 'sk-proj-0FanAyu0DKCwiLUaXQQCT3BlbkFJLGynCJLfVH1U720S2zM1'\n",
    "\n",
    "\n",
    "def audio_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_file)\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "        doc.close()\n",
    "    except Exception as e:\n",
    "        text = f\"Error extracting text from PDF: {str(e)}\"\n",
    "    return text\n",
    "\n",
    "\n",
    "def call_openai_api(prompt, max_tokens=150):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "\n",
    "\n",
    "def extract_keywords(text):\n",
    "    prompt = f\"Extract keywords from the following text:\\n\\n{text}\"\n",
    "    keywords = call_openai_api(prompt)\n",
    "    return keywords.split(', ')\n",
    "\n",
    "\n",
    "def text_similarity(text1, text2):\n",
    "    prompt = f\"Calculate the similarity between the following two texts:\\n\\nText 1: {text1}\\n\\nText 2: {text2}\\n\\nProvide a similarity score between 0 and 1.\"\n",
    "    similarity_score = call_openai_api(prompt)\n",
    "    return float(similarity_score)\n",
    "\n",
    "\n",
    "def extract_key_points(text):\n",
    "    prompt = f\"Extract key points from the following text:\\n\\n{text}\"\n",
    "    key_points = call_openai_api(prompt)\n",
    "    return key_points\n",
    "\n",
    "def keyword_matching(keywords1, keywords2):\n",
    "    prompt = f\"Compare the following two lists of keywords:\\n\\nKeywords 1: {', '.join(keywords1)}\\n\\nKeywords 2: {', '.join(keywords2)}\\n\\nReturn the matching keywords.\"\n",
    "    matching_keywords = call_openai_api(prompt)\n",
    "    return matching_keywords.split(', ')\n",
    "def analyze_sentiment(text):\n",
    "    prompt = f\"Analyze the sentiment of the following text:\\n\\n{text}\\n\\nProvide the sentiment score and the sentiment type (positive, negative, neutral).\"\n",
    "    sentiment_analysis = call_openai_api(prompt)\n",
    "    return sentiment_analysis\n",
    "\n",
    "\n",
    "def evaluate_explanation(text):\n",
    "    prompt = f\"Evaluate the explanation in the following text and provide suggestions for improvement:\\n\\n{text}\"\n",
    "    evaluation = call_openai_api(prompt)\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def main(audio_file, pdf_file):\n",
    " \n",
    "    audio_text = audio_to_text(audio_file)\n",
    "    \n",
    " \n",
    "    slides_text = extract_text_from_pdf(pdf_file)\n",
    "    \n",
    "  \n",
    "    key_points_audio = extract_key_points(audio_text)\n",
    "    key_points_slides = extract_key_points(slides_text)\n",
    "    \n",
    "    \n",
    "    similarity = text_similarity(audio_text, slides_text)\n",
    "    \n",
    "\n",
    "    audio_keywords = extract_keywords(audio_text)\n",
    "    slides_keywords = extract_keywords(slides_text)\n",
    "    \n",
    "\n",
    "    keyword_match = keyword_matching(audio_keywords, slides_keywords)\n",
    "    \n",
    "\n",
    "    audio_sentiment = analyze_sentiment(audio_text)\n",
    "    slides_sentiment = analyze_sentiment(slides_text)\n",
    "    \n",
    "   \n",
    "    explanation_evaluation = evaluate_explanation(audio_text)\n",
    "    \n",
    "    results = {\n",
    "        \"key_points_audio\": key_points_audio,\n",
    "        \"key_points_slides\": key_points_slides,\n",
    "        \"similarity\": similarity,\n",
    "        \"audio_keywords\": audio_keywords,\n",
    "        \"slides_keywords\": slides_keywords,\n",
    "        \"keyword_match\": keyword_match,\n",
    "        \"audio_sentiment\": audio_sentiment,\n",
    "        \"slides_sentiment\": slides_sentiment,\n",
    "        \"explanation_evaluation\": explanation_evaluation\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "audio_file = \"/Users/amiraalqabba/Desktop/ghadi.wav\"\n",
    "pdf_file = \"/Users/amiraalqabba/Desktop/Ecoswap.pdf\"\n",
    "\n",
    "results = main(audio_file, pdf_file)\n",
    "\n",
    "\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2c6850f-5abd-4c14-951b-33aa2909bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/anaconda3/lib/python3.12/site-packages (from openai==0.28) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from openai==0.28) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from openai==0.28) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (2024.6.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.9.3)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m346.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.35.10\n",
      "    Uninstalling openai-1.35.10:\n",
      "      Successfully uninstalled openai-1.35.10\n",
      "Successfully installed openai-0.28.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e75103ee-b8c6-42ad-808f-760d88e68656",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/amiraalqabba/Desktop/ghadi.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m pdf_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/amiraalqabba/Desktop/Ecoswap.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 74\u001b[0m results \u001b[38;5;241m=\u001b[39m main(audio_file, pdf_file)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# طباعة النتائج\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(results, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "Cell \u001b[0;32mIn[55], line 50\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(audio_file, pdf_file)\u001b[0m\n\u001b[1;32m     47\u001b[0m slides_text \u001b[38;5;241m=\u001b[39m extract_text_from_pdf(pdf_file)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# استخراج النقاط الرئيسية\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m key_points_audio \u001b[38;5;241m=\u001b[39m extract_key_points(audio_text)\n\u001b[1;32m     51\u001b[0m key_points_slides \u001b[38;5;241m=\u001b[39m extract_key_points(slides_text)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# حساب التشابه النصي\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[55], line 31\u001b[0m, in \u001b[0;36mextract_key_points\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_key_points\u001b[39m(text):\n\u001b[1;32m     30\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract key points from the following text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 31\u001b[0m     key_points \u001b[38;5;241m=\u001b[39m call_openai_api(prompt)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key_points\n",
      "Cell \u001b[0;32mIn[55], line 10\u001b[0m, in \u001b[0;36mcall_openai_api\u001b[0;34m(prompt, max_tokens)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_openai_api\u001b[39m(prompt, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     11\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-003\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     13\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import speech_recognition as sr\n",
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "\n",
    "\n",
    "openai.api_key = 'sk-proj-0bORuiaKJ1Zg0481roPNT3BlbkFJlqb18DqeJPin13CVgzW5'\n",
    "\n",
    "def call_openai_api(prompt, max_tokens=150):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_file)\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "        doc.close()\n",
    "    except Exception as e:\n",
    "        text = f\"Error extracting text from PDF: {str(e)}\"\n",
    "    return text\n",
    "\n",
    "def extract_key_points(text):\n",
    "    prompt = f\"Extract key points from the following text:\\n\\n{text}\"\n",
    "    key_points = call_openai_api(prompt)\n",
    "    return key_points\n",
    "\n",
    "def calculate_text_similarity(text1, text2):\n",
    "    prompt = f\"Calculate the similarity between the following two texts:\\n\\nText 1: {text1}\\n\\nText 2: {text2}\"\n",
    "    similarity_score = call_openai_api(prompt)\n",
    "    return similarity_score\n",
    "\n",
    "def detect_ignored_points(slides_text, audio_text):\n",
    "    prompt = f\"Identify points mentioned in the slides but ignored in the audio text.\\n\\nSlides Text: {slides_text}\\n\\nAudio Text: {audio_text}\"\n",
    "    ignored_points = call_openai_api(prompt)\n",
    "    return ignored_points\n",
    "\n",
    "def main(audio_file, pdf_file):\n",
    "  \n",
    "    audio_text = audio_to_text(audio_file)\n",
    "    slides_text = extract_text_from_pdf(pdf_file)\n",
    "\n",
    " \n",
    "    key_points_audio = extract_key_points(audio_text)\n",
    "    key_points_slides = extract_key_points(slides_text)\n",
    "\n",
    "  \n",
    "    text_similarity = calculate_text_similarity(audio_text, slides_text)\n",
    "  ignored_points = detect_ignored_points(slides_text, audio_text)\n",
    "\n",
    "    results = {\n",
    "        \"audio_text\": audio_text,\n",
    "        \"slides_text\": slides_text,\n",
    "        \"key_points_audio\": key_points_audio,\n",
    "        \"key_points_slides\": key_points_slides,\n",
    "        \"text_similarity\": text_similarity,\n",
    "        \"ignored_points\": ignored_points\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "audio_file = \"/Users/amiraalqabba/Desktop/ghadi.wav\"\n",
    "pdf_file = \"/Users/amiraalqabba/Desktop/Ecoswap.pdf\"\n",
    "\n",
    "results = main(audio_file, pdf_file)\n",
    "\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0d669-0135-484e-b917-6178ad56725a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e3cc7-f2b2-478e-a6b7-9a39ec3aa20f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
